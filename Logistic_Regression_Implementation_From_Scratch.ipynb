{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression Implementation From Scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3znoIuh_xb46",
        "colab_type": "text"
      },
      "source": [
        "# LOGISTIC REGRESSION IMPLEMENTATION FROM SCRATCH!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHGDEtJBxm__",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression** is a classification algorithm. It is derived from a linear regression line by restricting the range to 0 to 1 and converting it into a sigmoid curve.\n",
        "\n",
        "We know, linear regression has the following equation : \n",
        "\n",
        "**y = mx + c**\n",
        "\n",
        "We can convert it to a sigmoid curve by using the following formula : \n",
        "\n",
        "**y = 1/(1 + e^(-(mx + c)))** or **y = 1/(1 + e^(-y))**\n",
        "\n",
        "Sigmoid curve is a s-shaped curve used to determine the probability of an event. In logistic regression, basically we have two classes (1 or 0) to classify our data into and hence is also know as binary classification algorithm. The sigmoid curve provides us the probability. If the probability is **>=0.5** (i.e, threshold value) we classify the data as 1, 0 otherwise. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3DPfagj0dnf",
        "colab_type": "text"
      },
      "source": [
        "To begin with, we first import the dependencies and store the dataset int a variable named df. Here, we use the **Breast Cancer Type Prediction Dataset** downloaded from kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YymGF6z-M3WX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "46932c26-dfba-460f-f5ce-1574056bc86a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1fuv_mnNRaw",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "dc193b83-ab7c-46b5-81dd-1261dbed22d7"
      },
      "source": [
        "from google.colab import files\n",
        "up = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9c2b55c-bbea-44d6-8f16-05e28ecf4f89\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9c2b55c-bbea-44d6-8f16-05e28ecf4f89\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Breast Cancer Type Pred.csv to Breast Cancer Type Pred.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJJf5v1RNmRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8c166ee7-1aeb-438e-9816-1f4fda230150"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(up['Breast Cancer Type Pred.csv']))\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-i5WOfU1MNL",
        "colab_type": "text"
      },
      "source": [
        "Now, that we have imported the data, we start processing the data, i.e, **DATA WRANGLING**.\n",
        "\n",
        "First we drop the 'Unnamed: 32' column as it has mostly null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H-dUru8N7Y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa58f3de-7129-498a-dd30-ccf21ff6265c"
      },
      "source": [
        "df['Unnamed: 32'].isnull().value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True    569\n",
              "Name: Unnamed: 32, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zokA8ayN1jF8",
        "colab_type": "text"
      },
      "source": [
        "Next, we encode the 'diagnosis' columns and concat it to the original data. We also drop columns of less significance along with 'diagnosis' column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jF4LSBzOPDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "edb5c908-e5c6-442b-ccd1-cc90e8769641"
      },
      "source": [
        "dia = pd.get_dummies(df['diagnosis'], drop_first = True)\n",
        "df = pd.concat([df, dia], axis = 1)\n",
        "\n",
        "df.drop(['id', 'diagnosis', 'Unnamed: 32'], axis = 1, inplace = True)\n",
        "\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  fractal_dimension_worst  M\n",
              "0        17.99         10.38  ...                  0.11890  1\n",
              "1        20.57         17.77  ...                  0.08902  1\n",
              "2        19.69         21.25  ...                  0.08758  1\n",
              "3        11.42         20.38  ...                  0.17300  1\n",
              "4        20.29         14.34  ...                  0.07678  1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahk_zQ6c17IK",
        "colab_type": "text"
      },
      "source": [
        "At the end we have the target column - 'M' - which if 1 indicates that the tumor is malignant and and begnin if 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqboA70l2RCI",
        "colab_type": "text"
      },
      "source": [
        "Now, we create a function called **dataset_minmax()** which finds out the minumum and maximum vakues of our data and returns a list containing the minimum element at index 0 and maximum element at index 1.\n",
        "\n",
        "Variable Description: \n",
        "\n",
        "**d** = dataset\n",
        "\n",
        "**r** = row values of the dataset\n",
        "\n",
        "**m** = list storing the extremum values\n",
        "\n",
        "**col_values** = stores a column\n",
        "\n",
        "**value_min** = stores the minimum value\n",
        "\n",
        "**value_max** = stores the max value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGUlv7hQQBvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def minmax(d):\n",
        "\tm = list()\n",
        "\tfor i in range(len(d[0])):\n",
        "\t\tcol_values = [r[i] for r in d]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tm.append([value_min, value_max])\n",
        "\treturn m"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AetgVbS72oLF",
        "colab_type": "text"
      },
      "source": [
        "Then, we create a function **normalize_dataset()** to normalize our data. We do so, in order for the gradient update function to work correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvqcHQRIQRYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(d, m):\n",
        "\tfor r in d:\n",
        "\t\tfor i in range(len(r)):\n",
        "\t\t\tr[i] = (r[i] - m[i][0]) / (m[i][1] - m[i][0])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tf1czo3hR5",
        "colab_type": "text"
      },
      "source": [
        "Moving on we convert our data into array and find out our min and max values. And then we finally normalize our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiMXG-x3ZuXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = np.array(df)\n",
        "m = minmax(df[:,:-1])\n",
        "normalize(df[:,:-1], m)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hotqRWPa3fw_",
        "colab_type": "text"
      },
      "source": [
        "And next, we split our dataset into train and test dataset.\n",
        "\n",
        "Variable Description:\n",
        "\n",
        "**dtr** = training dataset\n",
        "\n",
        "**dte** = testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R1GiFMGbM-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtr, dte = train_test_split(df, test_size = 0.33)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3d1oFhjbUEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f1bac58-452f-48fc-c200-ef4b94334682"
      },
      "source": [
        "print(dtr.shape, dte.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(381, 31) (188, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYTPEPPk4Cnp",
        "colab_type": "text"
      },
      "source": [
        "Now, we create a function called **predict()** which will make predictions for our dataset.\n",
        "\n",
        "Variable Description:\n",
        "\n",
        "**r** = a row from our dataset\n",
        "\n",
        "**coeff** = linear regression coefficients for our dataset\n",
        "\n",
        "**y** = stores the value for the linear regression equation for our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__D3ziD4bWve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(r, coeff):\n",
        "\ty = coeff[0]\n",
        "\tfor i in range(len(r)-1):\n",
        "\t\ty += coeff[i + 1] * r[i]\n",
        "\treturn 1.0 / (1.0 + np.exp(-y))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-89KrlR-Plk",
        "colab_type": "text"
      },
      "source": [
        "To upgrade our coefficients we create a function **coeff_grad_update()**.\n",
        "\n",
        "Variable Coefficients:\n",
        "\n",
        "**train** = training dataset\n",
        "\n",
        "**coef** = stores the coefficients of linear regression for our data\n",
        "\n",
        "**learning_rate** = custom intitialised variable to fix the rate of change of coefficients\n",
        "\n",
        "**epoch** = custom initialised variable to fix the number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2f3qqLPbjqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def coeff_grad_update(train, learning_rate, epoch):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor e in range(epoch):\n",
        "\t\tfor r in train:\n",
        "\t\t\ty = predict(r, coef)\n",
        "\t\t\terror = r[-1] - y\n",
        "\t\t\tcoef[0] = coef[0] + learning_rate * error * y * (1.0 - y)\n",
        "\t\t\tfor i in range(len(r)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] + learning_rate * error * y * (1.0 - y) * r[i]\n",
        "\treturn coef"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5KazVqa_SjJ",
        "colab_type": "text"
      },
      "source": [
        "Now, finally we create the **logistic_regression()** function to fir our data and make predictions,\n",
        "\n",
        "Variable Description:\n",
        "\n",
        "**test** = testing dataset\n",
        "\n",
        "**predictions** = stores the predictions made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_SoMtxGb09C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(train, test, learning_rate, epoch):\n",
        "\tpredictions = list()\n",
        "\tcoef = coeff_grad_update(train, learning_rate, epoch)\n",
        "\tfor r in test:\n",
        "\t\ty = predict(r, coef)\n",
        "\t\ty = round(y)\n",
        "\t\tpredictions.append(y)\n",
        "\treturn(predictions)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkXwpzVDcAdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = logistic_regression(dtr, dte, 0.1, 100)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSt7Bdh-AGk-",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the predictions we check the quality of our MODEL!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65UsIzO6ANMt",
        "colab_type": "text"
      },
      "source": [
        "## CONFUSION MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQNNJaywce86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzTZ5uVZco0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = dte[:,-1]\n",
        "cm = confusion_matrix(y_true, pred)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DMB8cuhecGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "6b8b9ba5-ae0e-4b5a-ae0e-8173e273f4ba"
      },
      "source": [
        "titles = ['B', 'M']\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = titles, columns = titles)\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVJklrKuAUYC",
        "colab_type": "text"
      },
      "source": [
        "## CLASSIFICATION REPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "devq1r0OevK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d2b78a7b-e429-4445-cdff-a5a1782e59a6"
      },
      "source": [
        "print(classification_report(y_true, pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       123\n",
            "         1.0       1.00      0.95      0.98        65\n",
            "\n",
            "    accuracy                           0.98       188\n",
            "   macro avg       0.99      0.98      0.98       188\n",
            "weighted avg       0.98      0.98      0.98       188\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk0g-uz0DChn",
        "colab_type": "text"
      },
      "source": [
        "We observe that our model is working with a high rate of efficiency! We can use the above model for various classification dataset!\n",
        "\n",
        "# Thank You!!!"
      ]
    }
  ]
}